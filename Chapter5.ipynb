{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computational Mathematics\n",
    "## An Introduction to Numerical Analysis and Scientific Computing with Python\n",
    "### By Dimitrios Mitsotakis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5: Roots of Equations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very often, we need to solve an equation of the form\n",
    "\n",
    "$$ f(x) = 0 $$\n",
    "\n",
    "or, in other words, find the values of $x$ that satisfy the equation $f(x)=0$. If the equation is simple, we can solve this problem without the use of computers. However, when the equation is complicated or nonlinear, we usually cannot find an analytical solution.\n",
    "\n",
    "We will focus on numerical methods for approximating the root of a general equation $f(x)=0$. Specifically, we will study the Bisection, Newton-Raphson, and Secant methods. We will also explore combinations of these methods. Additionally, we will examine the convergence of the algorithms and learn how to implement and use them in Python.\n",
    "\n",
    "Let's start with the Bisection method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Bisection Method\n",
    "\n",
    "The Bisection method is based on Bolzano's theorem of Calculus (intermediate value theorem):\n",
    "\n",
    "**Theorem**: \n",
    "\n",
    "\n",
    "If a function $f(x)$ satisfies the following conditions:\n",
    "\n",
    "- $f$ is continuous in $[a,b]$\n",
    "- $f(a) \\cdot f(b) < 0$\n",
    "\n",
    "then there exists at least one solution $x^\\ast\\in (a,b)$ of the equation $f(x)=0$ \n",
    "This means that the function changes sign in the interval $[a,b]$ and $\\text{sign}(f(a)) \\not= \\text{sign}(f(b))$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Bisection method** is used to find a very small interval $[a,b]$ that contains the root of the equation $f(x)=0$ and the approximate solution is defined to be the midpoint of that interval $(a+b)/2$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bisection algorithm\n",
    "\n",
    "Given a bracket $[a,b]$ and a function $f(x)$ \n",
    "\n",
    "1. Set a tolerance `TOL` for accuracy\n",
    "2. Initialize the interval $[a,b]$\n",
    "3. Set $k=0$\n",
    "3. Check if $f(a)\\cdot f(b)<0$ (if not then quit)\n",
    "4. while `|b-a|>TOL` do\n",
    "   - Set `x_k = (a+b)/2` (the new approximation)\n",
    "   - Check in which interval $[a,x_k]$ or $[x_k,b]$ the function changes sign\n",
    "   - if $f(k_x)\\cdot f(a)<0$ then\n",
    "       - $b=x_k$\n",
    "   - else if $f(x_k)\\cdot f(b)<0$ then\n",
    "       - $a=x_k$\n",
    "   - else\n",
    "       - Break the loop because $f(x_k)=0$\n",
    "   - end if\n",
    "   - $k=k+1$\n",
    "5. end while\n",
    "6. Return the approximation of the root $x^\\ast$\n",
    "\n",
    "\n",
    "And here is a python implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bisection(f, a, b, tol = 1.e-6):\n",
    "    iteration = 0 #initialize counter iteration\n",
    "    if (f(a) * f(b) < 0.0): # check if there is a root\n",
    "        while ((b-a) > tol): # check if the end-points converge\n",
    "            iteration = iteration + 1\n",
    "            x = (a + b)/2\n",
    "            if (f(a) * f(x) < 0.0):\n",
    "                b = x\n",
    "            elif (f(x) * f(b) < 0.0):\n",
    "                a = x\n",
    "            else:\n",
    "                break\n",
    "            print(iteration, x)\n",
    "    else:\n",
    "        print('failure') \n",
    "    return x \n",
    "# returns the midpoint of the final interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try our method now for the equation\n",
    "$$ \\ln x + x = 0 $$\n",
    "in the inteval $[0.1,1]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.55\n",
      "2 0.775\n",
      "3 0.6625000000000001\n",
      "4 0.6062500000000001\n",
      "5 0.578125\n",
      "6 0.5640625\n",
      "7 0.57109375\n",
      "8 0.567578125\n",
      "9 0.5658203125000001\n",
      "10 0.5666992187500001\n",
      "11 0.567138671875\n",
      "12 0.5673583984375\n",
      "13 0.56724853515625\n",
      "14 0.567193603515625\n",
      "The aproximate solution is:  0.567193603515625\n",
      "And the error is:  0.0001390223881425623\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def f(x):\n",
    "    y = np.log(x) + x\n",
    "    return y\n",
    "\n",
    "a = 0.1\n",
    "b = 1.0\n",
    "tol = 1.e-4\n",
    "x = bisection(f, a, b, tol)\n",
    "print('The aproximate solution is: ', x)\n",
    "print('And the error is: ', f(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Evaluating the value $f(x^\\ast)$ we observe that the approximate solution satisfies the equation $f(x)=0$ with 4 decimal digitis correct. This is because we chose `tol = 1.e-4`. Try using smaller values of the variable `tol`.\n",
    "- We also observe that to achieve the requested accuracy the method required 14 iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental convergence rate\n",
    "\n",
    "In order to estimate the convergence rate, we compute the errors for three subsequent iterations, let's say $e_1, e_2, e_3$. Then we assume that\n",
    "\n",
    "$$|e_2|=C|e_1|^r$$\n",
    "$$|e_3|=C|e_2|^r$$\n",
    "\n",
    "Dividing the previous equations we have\n",
    "\n",
    "$$\\frac{|e_2|}{|e_3|}=\\left(\\frac{|e_1|}{|e_2|}\\right)^r$$\n",
    "\n",
    "We then we solve for $n$ to obtain the formula\n",
    "\n",
    "$$r = \\frac{\\log\\frac{|e_2|}{|e_3|}}{\\log\\frac{|e_1|}{|e_2|}}$$\n",
    "\n",
    "We modify the `bisection` function in order to compute the convergence rates numerically, and we try using the same problem as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bisection_rates(f, a, b, tol = 1.e-6):\n",
    "    iteration = 0\n",
    "    if (f(a) * f(b) < 0.0):\n",
    "        e1 = abs(b-a) #initialize e1 arbitrarily\n",
    "        e2 = e1*2 #initialize e2  arbitrarily\n",
    "        e3 = e1 #initialize e3 arbitrarily\n",
    "        while ((b-a)>tol):\n",
    "            e1 = e2\n",
    "            e2 = e3\n",
    "            iteration = iteration + 1\n",
    "            x = (a + b)/2\n",
    "            if (f(a) * f(x) < 0.0):\n",
    "                b = x\n",
    "            elif (f(x) * f(b) < 0.0):\n",
    "                a = x\n",
    "            else:\n",
    "                break\n",
    "            e3 = np.abs(b-a)\n",
    "            rate = np.log(e2/e3)/np.log(e1/e2)\n",
    "            print('iteration = ', iteration, 'rate =', rate)\n",
    "    else:\n",
    "         print('failure')\n",
    "     \n",
    "    return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration =  1 rate = 1.0000000000000002\n",
      "iteration =  2 rate = 0.9999999999999997\n",
      "iteration =  3 rate = 0.9999999999999993\n",
      "iteration =  4 rate = 1.0000000000000007\n",
      "iteration =  5 rate = 1.0000000000000029\n",
      "iteration =  6 rate = 0.9999999999999971\n",
      "iteration =  7 rate = 1.0000000000000115\n",
      "iteration =  8 rate = 0.9999999999999657\n",
      "iteration =  9 rate = 1.0000000000000682\n",
      "iteration =  10 rate = 0.9999999999999545\n",
      "iteration =  11 rate = 0.9999999999998177\n",
      "iteration =  12 rate = 1.0000000000001823\n",
      "iteration =  13 rate = 1.0000000000007292\n",
      "iteration =  14 rate = 0.9999999999992709\n",
      "The approximate solution x is:  0.567193603515625\n",
      "And the value f(x) is:  0.0001390223881425623\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    y = np.log(x) + x\n",
    "    return y\n",
    "\n",
    "a = 0.1\n",
    "b = 1.0\n",
    "tol = 1.e-4\n",
    "\n",
    "x = bisection_rates(f, a, b, tol)\n",
    "print('The approximate solution x is: ', x)\n",
    "print('And the value f(x) is: ', f(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify theoretically that for the previous example we need 14 iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next lesson we continue with more sophisticated numerical methods for obtaining faster and more accurate approximations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixed Point Methods \n",
    "\n",
    " - Given an interval, bisection is guaranteed to converge to a root\n",
    " - However bisection uses almost no information about $f(x)$ beyond its sign at a point\n",
    " \n",
    "**Basic Idea**: Every equation of the form $f(x)=0$ can be written equivalentrly in the form $x=g(x)$ in many different ways\n",
    "\n",
    "**Definition:** A point $x^\\ast$ in the domain of the function $g$ is called **fixed point** if $x^\\ast=g(x^\\ast)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construction of the iterative method\n",
    "\n",
    "- We need to construct an algorithm for the computation of the fixed points of $g$\n",
    "- But first, given an equation $f(x)=0$ we need to define the function $g(x)$\n",
    "- There is **not** a unique way to define the function $g$\n",
    "- After defining the function $g$ and in order to devise an iterative algorithm to solve the equation $x=g(x)$ we consider an initial guess $x_0\\approx x^\\ast$\n",
    "- We hope that this method will converge faster than the bisection method\n",
    "- A good initial condition could be the result of the bisection method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The fixed point algorithm\n",
    "\n",
    "Suppose that $g(x)$ is given. Given an initial guess $x_0$, the **Fixed point iteration** is defined as\n",
    "$$x_{k+1}=g(x_k), \\quad k=0,1,2,\\ldots$$\n",
    "which a sequence of approximation $x_0,x_1,x_2,\\cdots$\n",
    "\n",
    "1. Set a tolerance $TOL$ for the accuracy\n",
    "2. Set $k=0$\n",
    "3. Initialize $x_k$\n",
    "4. Set $Error=TOL+1$\n",
    "5. while $Error>TOL$ do\n",
    "  - Compute $x_{k+1}=g(x_k)$\n",
    "  - Set $Error=|x_{k+1}-x_k|$\n",
    "  - Increase the counter $k=k+1$\n",
    " 6. end while\n",
    " 7. Return the approximation of the root $x^\\ast$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixedpoint(g, x0, tol = 1.e-6, maxit = 100):\n",
    "    # g = the function g(x)\n",
    "    # x0 = the initial guess of the fixed point x=g(x)\n",
    "    # tol = tolerance for the absolute error\n",
    "    #         of two subsequent approximations\n",
    "    # maxit = maximum number of iterations allowed\n",
    "    error = 1.0\n",
    "    iteration = 0\n",
    "    xk = x0\n",
    "    while (error > tol and iteration < maxit):\n",
    "        iteration = iteration + 1\n",
    "        error = xk\n",
    "        xk = g(xk)\n",
    "        error = np.abs(error - xk)\n",
    "        print ('iteration =', iteration, ', x =', xk)\n",
    "    return xk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we try the code for the function $f(x)=x^2-x-1$ using $g(x)=\\sqrt{x+1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration = 1 , x = 1.0\n",
      "iteration = 2 , x = 1.4142135623730951\n",
      "iteration = 3 , x = 1.5537739740300374\n",
      "iteration = 4 , x = 1.5980531824786175\n",
      "iteration = 5 , x = 1.6118477541252516\n",
      "iteration = 6 , x = 1.616121206508117\n",
      "iteration = 7 , x = 1.6174427985273905\n",
      "iteration = 8 , x = 1.617851290609675\n",
      "iteration = 9 , x = 1.6179775309347393\n",
      "iteration = 10 , x = 1.6180165422314876\n",
      "The approximate solution x is:  1.6180165422314876\n",
      "And the value f(x) is:  -3.9011296748103774e-05\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    y = x**2-x-1.0\n",
    "    return y\n",
    "def g(x):\n",
    "    y = np.sqrt(x+1.0)\n",
    "    return y\n",
    "tol = 1.e-4\n",
    "maxit = 50\n",
    "x0 = 0.0\n",
    "x = fixedpoint(g, x0, tol, maxit)\n",
    "print('The approximate solution x is: ', x)\n",
    "print('And the value f(x) is: ', f(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try to solve the same equation $f(x)=0$ but now with $g(x)=1+1/x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration = 1 , x = 2.0\n",
      "iteration = 2 , x = 1.5\n",
      "iteration = 3 , x = 1.6666666666666665\n",
      "iteration = 4 , x = 1.6\n",
      "iteration = 5 , x = 1.625\n",
      "iteration = 6 , x = 1.6153846153846154\n",
      "iteration = 7 , x = 1.619047619047619\n",
      "iteration = 8 , x = 1.6176470588235294\n",
      "iteration = 9 , x = 1.6181818181818182\n",
      "iteration = 10 , x = 1.6179775280898876\n",
      "iteration = 11 , x = 1.6180555555555556\n",
      "The approximate solution x is:  1.6180555555555556\n",
      "And the value f(x) is:  4.822530864223573e-05\n"
     ]
    }
   ],
   "source": [
    "def g(x):\n",
    "    y = 1.0+1.0/x\n",
    "    return y\n",
    "tol = 1.e-4\n",
    "maxit = 50\n",
    "x0 = 1.0\n",
    "x = fixedpoint(g, x0, tol, maxit)\n",
    "print('The approximate solution x is: ', x)\n",
    "print('And the value f(x) is: ', f(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try using the functions\n",
    "$$g(x)=x^2-1$$\n",
    "and\n",
    "$$g(x)=x-\\frac{x^2-x-1}{2x-1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Newton's Method (Newton-Raphson)\n",
    " \n",
    "**Basic Idea**: Given $f(x)$ and $f'(x)$ and and initial guess $x_0$, find the root of the tangent line to $(x_0,f(x_0))$ to find $x_1\\approx x^*$. Continue using $x_1$ to compute $x_2$, etc.\n",
    "\n",
    "Given $x_k$, then the next approximation of the root $x^\\ast$ defined by Newton's method is:\n",
    "$$\n",
    "    x_{k+1} = x_k-\\frac{f(x_k)}{f'(x_k)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Newton's method algorith \n",
    "\n",
    "1. Set a tolerance $TOL$ for the accuracy\n",
    "2. Set the maximum number of iteration $MAXIT$ \n",
    "3. Set $k=0$\n",
    "4. Initialize $x_k$ and $Error=TOL+1$\n",
    "5. while $Error>TOL$ and $k<MAXIT$ do\n",
    "    - if $f'(x_k)\\not=0$ then\n",
    "        - Compute $x_{k+1}=x_k-\\frac{f(x_k)}{f'(x_{k})}$\n",
    "        - Set $Error = |x_{k+1}-x_k|$\n",
    "        - Increase the counter $k=k+1$\n",
    "    - end if\n",
    "6. end while\n",
    "7. Return the approximation of the root $x^\\ast$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton(f, df, x0, tol = 1.e-6, maxit = 100):\n",
    "    # f = the function f(x)\n",
    "    # df = the derivative of f(x)\n",
    "    # x0 = the initial guess of the solution\n",
    "    # tol = tolerance for the absolute error\n",
    "    # maxit = maximum number of iterations\n",
    "    err = tol+1.0\n",
    "    iteration = 0\n",
    "    xk = x0\n",
    "    while (err > tol and iteration < maxit):\n",
    "        iteration = iteration + 1\n",
    "        err = xk # store previous approximation to err\n",
    "        xk = xk - f(xk)/df(xk) # Newton's iteration\n",
    "        err = np.abs(err - xk) # compute the new error\n",
    "        print(iteration, xk)\n",
    "    return xk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try our method for the equation\n",
    "$$ \\ln x + x = 0 $$\n",
    "\n",
    "Note that here we don't need to specify an initial interval but an initial guess, which we take to be $x_0=1$. \n",
    "\n",
    "In this case $f(x)=\\ln x + x$ and $f'(x)=\\frac{1}{x} + 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.5\n",
      "2 0.5643823935199818\n",
      "3 0.5671389877150601\n",
      "4 0.5671432903993691\n",
      "The aproximate solution is:  0.5671432903993691\n",
      "And the error is:  -2.877842408821607e-11\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    y = np.log(x) + x\n",
    "    return y\n",
    "def df(x):\n",
    "    y = 1.0 / x + 1.0\n",
    "    return y\n",
    "tol = 1.e-4\n",
    "maxit = 50\n",
    "x0 = 1.0\n",
    "x = newton(f, df, x0, tol, maxit)\n",
    "print('The aproximate solution is: ', x)\n",
    "print('And the error is: ', f(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rate of convergence for Newton's method is $r=2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Secant Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The secant method can be obtained from Newton's method with the approximation of the first derivative\n",
    "$$f'(x_k)=\\frac{f(x_k)-f(x_{k-1})}{x_k-x_{k-1}}$$\n",
    "\n",
    "The new iteration is the defined\n",
    "Given $x_k$ and $x_{k-1}\n",
    "$$x_{k+1}=x_k-\\frac{x_k-x_{k-1}}{f(x_k)-f(x_{k-1})}f(x_k)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Secant method algorithm \n",
    "\n",
    "1. Set a tolerance $TOL$ for the accuracy\n",
    "2. Set the maximum number of iteration $MAXIT$ \n",
    "4. Initialize $x_{k-1}$ and $x_k$ and set $k=0$\n",
    "5. Set $Error=TOL+1$\n",
    "6. while $Error>TOL$ and $k<MAXIT$ do\n",
    "    - if $f'(x_k)\\not=0$ then\n",
    "        - Compute $x_{k+1}=x_k-\\frac{x_k-x_{k-1}}{f(x_k)-f(x_{k-1})}f(x_k)$\n",
    "        - Set $Error = |x_{k+1}-x_k|$\n",
    "        - Increase the counter $k=k+1$\n",
    "    - end if\n",
    "7. end while\n",
    "8. Return the approximation of the root $x^\\ast$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def secant(f, x1, x2, tol = 1.e-6, maxit = 100):\n",
    "    # f = the function f(x)\n",
    "    # x1 = an initial guess of the solution\n",
    "    # x2 = another initial guess of the solution\n",
    "    # tol = tolerance for the absolute error\n",
    "    # maxit = maximum number of iterations\n",
    "    err = 1.0\n",
    "    iteration = 0\n",
    "    while (err > tol and iteration < maxit):\n",
    "        xk1 = x1\n",
    "        xk = x2\n",
    "        iteration = iteration + 1\n",
    "        err = xk1\n",
    "        xk1 = xk - (xk-xk1)/(f(xk)-f(xk1))*f(xk)\n",
    "        err = np.abs(err - xk1)\n",
    "        x1 = x2\n",
    "        x2 = xk1\n",
    "        print(iteration, xk1)\n",
    "    return xk1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing this new method for the equation\n",
    "$$ \\ln x + x = 0\\ , $$\n",
    "with initial guesses $x_{-1}=1$ and $x_{0}=2$ we obtain the following results: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.40938389085035864\n",
      "2 0.651575386390747\n",
      "3 0.5751035382227284\n",
      "4 0.5667851889083253\n",
      "5 0.5671448866112347\n",
      "6 0.5671432907314143\n",
      "7 0.5671432904097836\n",
      "The approximate solution is:  0.5671432904097836\n",
      "And the error is:  -6.661338147750939e-16\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    y = np.log(x) + x\n",
    "    return y\n",
    "tol = 1.e-4\n",
    "maxit = 50\n",
    "x1 = 1.0\n",
    "x2 = 2.0\n",
    "x = secant(f, x1, x2, tol, maxit)\n",
    "print('The approximate solution is: ', x)\n",
    "print('And the error is: ', f(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rate of convergence for the secant method is the golder ratio $r=\\frac{1+\\sqrt{5}}{2}\\approx 1.61<2$ and thus is a bit slower than Newton's method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Module `scipy.optimize`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bisection method is implemented in the function `bisect` of the module `scipy.optimize`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The approximate solution x is:  0.567193603515625\n",
      "And the value f(x) is:  0.0001390223881425623\n"
     ]
    }
   ],
   "source": [
    "import scipy.optimize as spo\n",
    "def f(x):\n",
    "    y = np.log(x)+x\n",
    "    return y\n",
    "a = 0.1\n",
    "b = 1.0\n",
    "tol = 1.e-4\n",
    "x = spo.bisect(f, a, b, () , tol)\n",
    "print('The approximate solution x is: ', x)\n",
    "print('And the value f(x) is: ', f(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generaic fixed-point method is also implemented in `scipy.optimize` in the function `fixed_point`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The approximate solution x is:  1.6180339887498991\n",
      "And the value f(x) is:  9.547918011776346e-15\n"
     ]
    }
   ],
   "source": [
    "import scipy.optimize as spo\n",
    "def f(x):\n",
    "    y = x**2-x-1.0\n",
    "    return y\n",
    "def g(x):\n",
    "    y = np.sqrt(x+1.0)\n",
    "    return y\n",
    "x0 = 1.0\n",
    "tol = 1.e-4\n",
    "maxit = 50\n",
    "x = spo.fixed_point(g, x0, (), tol, maxit)\n",
    "print('The approximate solution x is: ', x)\n",
    "print('And the value f(x) is: ', f(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the Newton and Secant methods are implemented in the function `newton` of `scipy.optimize`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The approximate solution x is:  0.5671432903993691\n",
      "And the value f(x) is:  -2.877842408821607e-11\n"
     ]
    }
   ],
   "source": [
    "import scipy.optimize as spo\n",
    "def f(x):\n",
    "    y = np.log(x)+x\n",
    "    return y\n",
    "def df(x):\n",
    "    y = 1.0/x+1.0\n",
    "    return y\n",
    "x0 = 1.0\n",
    "x = spo.newton(f, x0, df, tol=1.e-4, maxiter=50)\n",
    "print('The approximate solution x is: ', x)\n",
    "print('And the value f(x) is: ', f(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `scipy.optimize` one can find also a hybrid method that works in a more broader spectrum of problems compared to the previous implementation. This method is implemented in the function `fsolve`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The approximate solution x is:  [0.56714329]\n",
      "And the value f(x) is:  [3.4803842e-09]\n"
     ]
    }
   ],
   "source": [
    "import scipy.optimize as spo\n",
    "def f(x):\n",
    "    y = np.log(x)+x\n",
    "    return y\n",
    "def df(x):\n",
    "    y = 1.0/x+1.0\n",
    "    return y\n",
    "x0 = 1.0\n",
    "x = spo.fsolve(f, x0, fprime=df, xtol=1.e-4)\n",
    "print('The approximate solution x is: ', x)\n",
    "print('And the value f(x) is: ', f(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application in Astrophysics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $\\psi$ is the mean anomaly of the orbit of a plant, then $\\theta$, the eccentric anomaly, can be computed by solving the fixed point equation\n",
    "$$\\theta=\\psi+e\\sin \\theta$$\n",
    "where $e$ is the eccentricity of the elliptical orbit.\n",
    "\n",
    "This equation can be solved seamlesly using the funtion `fixed_point` of `scipy.optimize`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eccentric anomaly= 0.5235992755987319\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.optimize as spo\n",
    "def g(theta):\n",
    "    e = 1.e-6\n",
    "    psi = np.pi/6.0\n",
    "    return psi+e*np.sin(theta)\n",
    "theta0 = np.pi/6.0\n",
    "theta = spo.fixed_point(g, theta0)\n",
    "print('eccentric anomaly=', theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing the eccentric anomaly can lead to the estimation of the heliocentric distance $r=a(1-e\\cos\\theta)$ where $a$ is the semi-major axis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
